import requests
import pandas as pd
import os
from bs4 import BeautifulSoup
from io import StringIO

URL = "https://tradestat.commerce.gov.in/eidb/country_wise_ttrade"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_CSV = os.path.join(BASE_DIR, "../../data/trade_stats.csv")

def get_trade_data():
    # Fetch page
    response = requests.get(URL)
    response.raise_for_status()

    # Parse HTML
    soup = BeautifulSoup(response.text, "lxml")
    table = soup.find("table")
    if not table:
        raise ValueError("No tables found on the page")

    # Pre-clean table HTML: remove problematic quotes
    for cell in table.find_all("td"):
        cell.string = cell.get_text(strip=True).replace('"', '').replace("'", "")

    # Convert cleaned table to string
    table_str = str(table)

    # Read with pandas
    df = pd.read_html(StringIO(table_str))[0]

    # Clean column names
    df.columns = [col.strip() for col in df.columns]

    # Ensure data folder exists
    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)

    # Save CSV safely
    df.to_csv(OUTPUT_CSV, index=False, quoting=pd.io.common.csv.QUOTE_NONNUMERIC)

    return df

if __name__ == "__main__":
    df = get_trade_data()
    print(df.head())
